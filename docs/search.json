[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Methods for Transport Planning - Workbook",
    "section": "",
    "text": "Preface\nWelcome to the Statistical Methods for Transport Planning (SMTP) Workbook!\nThis workbook is your hands-on companion to the main course. Inside, you’ll find a series of step-by-step activities designed to help you explore real-world transport data and put the concepts from the lectures into practice. Think of it as your space to experiment, apply what you’ve learned, and build confidence in using statistical methods for transport planning.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#pre-requisites",
    "href": "index.html#pre-requisites",
    "title": "Statistical Methods for Transport Planning - Workbook",
    "section": "Pre-requisites",
    "text": "Pre-requisites\nThe activities assume you already have R and RStudio installed in your machine.\nAlso, the activities assume prior knowledge R coding skills.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Statistical Methods for Transport Planning - Workbook",
    "section": "Contact",
    "text": "Contact\nJoseRafael.Verduzco-Torres@glasgow.ac.uk",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "session-1.html",
    "href": "session-1.html",
    "title": "1  Session 1. Working environment and formatting data",
    "section": "",
    "text": "1.1 Setting the working environment\nA good practice is to have an RStudio for each different project you are working on. This creates a folder in which, ideally, you should include all the input and output data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1. Working environment and formatting data</span>"
    ]
  },
  {
    "objectID": "session-1.html#setting-the-working-environment",
    "href": "session-1.html#setting-the-working-environment",
    "title": "1  Session 1. Working environment and formatting data",
    "section": "",
    "text": "Before moving any further, make sure you have your own RStudio project in your session. Staff will be more than happy to assist you here if needed.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1. Working environment and formatting data</span>"
    ]
  },
  {
    "objectID": "session-1.html#lets-practice-using-some-transport-data",
    "href": "session-1.html#lets-practice-using-some-transport-data",
    "title": "1  Session 1. Working environment and formatting data",
    "section": "1.2 Lets Practice using some transport data",
    "text": "1.2 Lets Practice using some transport data\nIn this course, we will look into Puget Sound Regional Travel Surve. This workbook uses dataset version ‘2023.5’.\n\nDownload the dataset available from the course Moodle page under the ‘Lab Activities’ tile.\nUnzip the file. You can see that the following tables in CSV files:\n\nTrips\nPersons\nHouseholds\nVehicles\nDays\n\nMove the files into your RStudio project. It is a good practice to keep inputs, code, and outputs separate. I suggest you to create a folder called data in your project folder and paste all the survey files in it.\n\nThe codebook is available on Moodle, too. Additional information offered by the source are available at https://www.psrc.org/our-work/household-travel-survey-program.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1. Working environment and formatting data</span>"
    ]
  },
  {
    "objectID": "session-1.html#hands-on",
    "href": "session-1.html#hands-on",
    "title": "1  Session 1. Working environment and formatting data",
    "section": "1.3 Hands on",
    "text": "1.3 Hands on\nThe objective of this first part is to reproduce the results shown below. For now, I encourage you to type the code, rather than copying, this can help you to actively think of what the code is doing.\nAs a first step, create an RMardown/Quarto file, and save it in your RStudio project (remove all the default contents, if included).\nFirst, load the packages required for the analysis (install if needed).\n\n# for data manipulation and visualization\nlibrary(tidyverse) \n\nThen, read the ‘Household’ table from the CSV file. Make sure to adjust the directory to match the location where you save the Survey files.\n\n# Reading the Household data\nhouseholds &lt;- read_csv(\"data/Households.csv\")\n\nA quick check. How many rows and columns are there in the dataset?\n\nnrow(households)\n\n[1] 12118\n\nncol(households)\n\n[1] 69\n\n\nThat’s many columns. Check the first first 20 variable names in the houshold table.\n\nhead(colnames(household), 20)\n\n[1] \"family\"      \"dob_child1\"  \"dob_child2\"  \"name_child1\" \"name_child2\"\n\n\nWhat do all these names mean?!\nDownload the dataset codebook from Moodle, and keep it in your project folder. Spend 5-10 minutes to explore the structure and get familiar with the contents of the dataset.\n\n1.3.1 Subsetting\nLets subset some variables of interest from the Household table. Also, keep the records for the year 2023 only.\n\n# Subset the data to select only the variables we need for the year 2023\nhousehold_subset &lt;- households %&gt;%\n  filter(survey_year == 2023) %&gt;%\n  select(\n    household_id, hhincome_broad, hhsize, \n    home_county, vehicle_count, hh_race_category, \n    numadults, numchildren, numworkers\n  )\n\nWe can glimpse the data to see the type of the variables are included.\n\nglimpse(household_subset)\n\nRows: 3,870\nColumns: 9\n$ household_id     &lt;dbl&gt; 23007083, 23007112, 23003118, 23007129, 23007152, 230…\n$ hhincome_broad   &lt;chr&gt; \"$75,000-$99,999\", \"$50,000-$74,999\", \"$25,000-$49,99…\n$ hhsize           &lt;chr&gt; \"3 people\", \"2 people\", \"1 person\", \"2 people\", \"3 pe…\n$ home_county      &lt;chr&gt; \"Kitsap County\", \"King County\", \"King County\", \"King …\n$ vehicle_count    &lt;chr&gt; \"4 vehicles\", \"1 vehicle\", \"1 vehicle\", \"1 vehicle\", …\n$ hh_race_category &lt;chr&gt; \"AANHPI non-Hispanic\", \"White non-Hispanic\", \"AANHPI …\n$ numadults        &lt;chr&gt; \"3 adults\", \"2 adults\", \"1 adult\", \"2 adults\", \"2 adu…\n$ numchildren      &lt;chr&gt; \"0 children\", \"0 children\", \"0 children\", \"0 children…\n$ numworkers       &lt;chr&gt; \"3 workers\", \"2 workers\", \"1 worker\", \"0 workers\", \"2…",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1. Working environment and formatting data</span>"
    ]
  },
  {
    "objectID": "session-1.html#formating-variables",
    "href": "session-1.html#formating-variables",
    "title": "1  Session 1. Working environment and formatting data",
    "section": "1.4 Formating variables",
    "text": "1.4 Formating variables\nSome columns are not in it’s appropriate type, as they mix text with numbers. Thus, we will have to extract the numbers and set categorical variables to factors.\n\nhousehold_subset &lt;- household_subset %&gt;%\n  mutate(\n    hhsize = parse_number(hhsize),\n    vehicle_count = parse_number(vehicle_count),\n    numadults = parse_number(numadults),\n    numchildren = parse_number(numchildren),\n    numworkers = parse_number(numworkers)\n  )\n\nCategorical variables as factors.\n\n# Convert all required variables to factors\nhousehold_subset &lt;- household_subset %&gt;%\n  mutate(\n    across(c(hhincome_broad, home_county, hh_race_category), \n    factor\n))\n\nLet’s glimpse the formatted variables.\n\nglimpse(household_subset)\n\nRows: 3,870\nColumns: 9\n$ household_id     &lt;dbl&gt; 23007083, 23007112, 23003118, 23007129, 23007152, 230…\n$ hhincome_broad   &lt;fct&gt; \"$75,000-$99,999\", \"$50,000-$74,999\", \"$25,000-$49,99…\n$ hhsize           &lt;dbl&gt; 3, 2, 1, 2, 3, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2,…\n$ home_county      &lt;fct&gt; Kitsap County, King County, King County, King County,…\n$ vehicle_count    &lt;dbl&gt; 4, 1, 1, 1, 1, 2, 1, 1, 2, 0, 1, 2, 1, 2, 1, 3, 1, 2,…\n$ hh_race_category &lt;fct&gt; AANHPI non-Hispanic, White non-Hispanic, AANHPI non-H…\n$ numadults        &lt;dbl&gt; 3, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2,…\n$ numchildren      &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ numworkers       &lt;dbl&gt; 3, 2, 1, 0, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1,…\n\n\nThe income bands are ordered categories. However, they are unordered. Rearrenge them as following:\nFormat the order of household income labels\n\n# Type ordered income labs\nincome_labs &lt;- c(\n  \"Under $25,000\", \n  \"$25,000-$49,999\", \n  \"$50,000-$74,999\", \n  \"$75,000-$99,999\", \n  \"$100,000-$199,999\", \n  \"$200,000 or more\"\n)\n\nhousehold_subset &lt;- household_subset %&gt;% \n  mutate(hhincome_broad = factor(hhincome_broad, levels = income_labs))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1. Working environment and formatting data</span>"
    ]
  },
  {
    "objectID": "session-1.html#descriptive-statistics",
    "href": "session-1.html#descriptive-statistics",
    "title": "1  Session 1. Working environment and formatting data",
    "section": "1.5 Descriptive statistics",
    "text": "1.5 Descriptive statistics\nWe can have a quick and dirt descriptive statistics overview by producing a default summary.\n\nsummary(household_subset)\n\n  household_id                hhincome_broad     hhsize     \n Min.   :23000173   Under $25,000    : 402   Min.   :1.000  \n 1st Qu.:23073829   $25,000-$49,999  : 490   1st Qu.:1.000  \n Median :23154700   $50,000-$74,999  : 509   Median :2.000  \n Mean   :23173722   $75,000-$99,999  : 423   Mean   :1.954  \n 3rd Qu.:23265921   $100,000-$199,999:1065   3rd Qu.:2.000  \n Max.   :23423045   $200,000 or more : 605   Max.   :9.000  \n                    NA's             : 376                  \n           home_county   vehicle_count  \n King County     :2793   Min.   :0.000  \n Kitsap County   : 215   1st Qu.:1.000  \n Pierce County   : 416   Median :1.000  \n Snohomish County: 446   Mean   :1.389  \n                         3rd Qu.:2.000  \n                         Max.   :8.000  \n                                        \n                               hh_race_category   numadults    \n AANHPI non-Hispanic                   : 667    Min.   :1.000  \n Black or African American non-Hispanic: 121    1st Qu.:1.000  \n Hispanic                              : 260    Median :2.000  \n Missing/No response                   : 640    Mean   :1.683  \n Some Other Races non-Hispanic         : 132    3rd Qu.:2.000  \n White non-Hispanic                    :2050    Max.   :9.000  \n                                                               \n  numchildren       numworkers   \n Min.   :0.0000   Min.   :0.000  \n 1st Qu.:0.0000   1st Qu.:0.000  \n Median :0.0000   Median :1.000  \n Mean   :0.2716   Mean   :1.107  \n 3rd Qu.:0.0000   3rd Qu.:2.000  \n Max.   :5.0000   Max.   :6.000  \n                                 \n\n\nFor tailored descriptive statistic summarise, we can do the following:\n\nhousehold_subset %&gt;% \n  summarise(hhsize_mean = mean(hhsize), hhsize_sd = sd(hhsize))\n\n# A tibble: 1 × 2\n  hhsize_mean hhsize_sd\n        &lt;dbl&gt;     &lt;dbl&gt;\n1        1.95      1.11\n\n\nAn we can easily extend this breaking down the descriptive statistics by group a categorical characteristic of the household. In the example below, by the home County.\n\n household_subset %&gt;% \n  group_by(home_county) %&gt;% \n  summarise(mean = mean(hhsize), sd = sd(hhsize))\n\n# A tibble: 4 × 3\n  home_county       mean    sd\n  &lt;fct&gt;            &lt;dbl&gt; &lt;dbl&gt;\n1 King County       1.87  1.06\n2 Kitsap County     2.18  1.12\n3 Pierce County     2.09  1.17\n4 Snohomish County  2.25  1.26\n\n\nTry summarising by hh_race_category.\nThese examples provide useful and flexible summaries. However, it’d require some work to format it for a final output. Packages that can help you creating descriptive statistic tables are: gtsummary, modelsummary, summarytools.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1. Working environment and formatting data</span>"
    ]
  },
  {
    "objectID": "session-1.html#missing-data",
    "href": "session-1.html#missing-data",
    "title": "1  Session 1. Working environment and formatting data",
    "section": "1.6 Missing data",
    "text": "1.6 Missing data\nExamine the variable hh_race_category. Are the missing values?\nFollowing the conventions in R, missing values should be treated as NA. Format these as appropriate using the fct_recode().\nThere are many reasons why some data might be missing.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1. Working environment and formatting data</span>"
    ]
  },
  {
    "objectID": "session-1.html#wraping-up",
    "href": "session-1.html#wraping-up",
    "title": "1  Session 1. Working environment and formatting data",
    "section": "1.7 Wraping up",
    "text": "1.7 Wraping up\n\n1.7.1 Write the formated subset\nWe will finish this session here.\nWe will write the formatted household subset. So, you do not have to go over the same steps in the next session.\n\nwrite_rds(household_subset,file = 'data/household_subset.RDS')\n\n\n\n1.7.2 Final reflections\n\nWhat year are you including in the data?\nWhat level of unit is represented in the table you prepared?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Session 1. Working environment and formatting data</span>"
    ]
  },
  {
    "objectID": "session-2.html",
    "href": "session-2.html",
    "title": "2  Session 2 Data structures and descriptive statistics",
    "section": "",
    "text": "2.1 Preliminaries\nFirst, load the packages required for the analysis (install if needed).\nlibrary(tidyverse) # for data manipulation and visualization\nWe will pick it up where we left it last time, and read the household data in the RDS file you prepared. If you haven’t completed Session 1, go to it and complete it before continuing here.\nhousehold_subset &lt;- read_rds('data/household_subset.RDS')\nYou will also need the ‘Trips’ table for this session. As we will combine the information from households and trips reported by each household.\ntrips &lt;- read_csv(\"data/Trips.csv\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Session 2 Data structures and descriptive statistics</span>"
    ]
  },
  {
    "objectID": "session-2.html#format-trips-table",
    "href": "session-2.html#format-trips-table",
    "title": "2  Session 2 Data structures and descriptive statistics",
    "section": "2.2 Format Trips table",
    "text": "2.2 Format Trips table\nSubset trips for the year 2023 and keep only variables of interest.\n\ntrips_subset &lt;- trips %&gt;%\n  filter(survey_year == 2023) %&gt;%\n  select(\n    household_id, person_id, trip_id, \n    mode_class, depart_date, depart_time_hour, \n    arrival_time_hour, origin_county, dest_county, \n    origin_purpose_cat, dest_purpose_cat, distance_meters,\n    duration_minutes\n)\n\nALWAYS CHECK THE SUBSET!!! What would you check?\n\nnrow(trips_subset)\n\n[1] 56704\n\nncol(trips_subset)\n\n[1] 13\n\n\n\ncolnames(trips_subset)\n\n [1] \"household_id\"       \"person_id\"          \"trip_id\"           \n [4] \"mode_class\"         \"depart_date\"        \"depart_time_hour\"  \n [7] \"arrival_time_hour\"  \"origin_county\"      \"dest_county\"       \n[10] \"origin_purpose_cat\" \"dest_purpose_cat\"   \"distance_meters\"   \n[13] \"duration_minutes\"  \n\nhead(trips_subset)\n\n# A tibble: 6 × 13\n  household_id  person_id       trip_id mode_class  depart_date depart_time_hour\n         &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt;       &lt;date&gt;                 &lt;dbl&gt;\n1     23000858 2300085801 2300085801002 Walk        2023-04-27                16\n2     23000466 2300046601 2300046601004 Walk        2023-04-20                14\n3     23001235 2300123501 2300123501011 Drive HOV3+ 2023-04-27                19\n4     23000466 2300046601 2300046601005 Walk        2023-04-20                14\n5     23000858 2300085801 2300085801003 Drive HOV2  2023-04-27                19\n6     23001235 2300123501 2300123501012 Drive HOV3+ 2023-04-27                19\n# ℹ 7 more variables: arrival_time_hour &lt;dbl&gt;, origin_county &lt;chr&gt;,\n#   dest_county &lt;chr&gt;, origin_purpose_cat &lt;chr&gt;, dest_purpose_cat &lt;chr&gt;,\n#   distance_meters &lt;dbl&gt;, duration_minutes &lt;dbl&gt;\n\n\nTransform the categorical variables as factor.\n\ntrips_subset &lt;- trips_subset %&gt;%\n  mutate(\n    across(\n      c(mode_class, origin_county, dest_county, origin_purpose_cat, dest_purpose_cat), \n      as.factor)\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Session 2 Data structures and descriptive statistics</span>"
    ]
  },
  {
    "objectID": "session-2.html#trip-descriptive-statistics",
    "href": "session-2.html#trip-descriptive-statistics",
    "title": "2  Session 2 Data structures and descriptive statistics",
    "section": "2.3 Trip descriptive statistics",
    "text": "2.3 Trip descriptive statistics\nCalculate a summary at the person-level. Include the number of trips, total travel distance and travel time for each person, within household.\n\nperson_summary &lt;- trips_subset %&gt;%\n  group_by(person_id, household_id) %&gt;%\n  summarise(\n    number_of_trips = n(),\n    # Distance in kilometres\n    total_travel_distance = sum(distance_meters / 1000),\n    total_travel_time = sum(duration_minutes)\n  ) %&gt;% \n  ungroup()\n\nNow, you need to normalise the total distance and travel time based on the number of trips by calculating the average values.\n\nperson_summary &lt;- person_summary %&gt;% \n  mutate(\n    avg_trip_distance = total_travel_distance / number_of_trips,\n    avg_trip_duration = total_travel_time / number_of_trips\n  )\n\nCreate a quick summary\n\nsummary(person_summary)\n\n   person_id          household_id      number_of_trips   total_travel_distance\n Min.   :2.300e+09   Min.   :23000173   Min.   :  2.000   Min.   :    0.066    \n 1st Qu.:2.307e+09   1st Qu.:23070124   1st Qu.:  2.000   1st Qu.:   11.425    \n Median :2.315e+09   Median :23153760   Median :  4.000   Median :   29.122    \n Mean   :2.317e+09   Mean   :23170889   Mean   :  9.509   Mean   :  124.803    \n 3rd Qu.:2.326e+09   3rd Qu.:23264171   3rd Qu.:  8.000   3rd Qu.:   79.841    \n Max.   :2.342e+09   Max.   :23423045   Max.   :307.000   Max.   :18795.769    \n                                                          NA's   :1            \n total_travel_time avg_trip_distance  avg_trip_duration\n Min.   :   2.0    Min.   :   0.033   Min.   :  1.00   \n 1st Qu.:  48.0    1st Qu.:   2.925   1st Qu.: 12.97   \n Median :  88.0    Median :   5.951   Median : 19.00   \n Mean   : 196.7    Mean   :  14.324   Mean   : 24.67   \n 3rd Qu.: 205.0    3rd Qu.:  12.080   3rd Qu.: 30.00   \n Max.   :2573.0    Max.   :2697.030   Max.   :270.50   \n NA's   :1         NA's   :1          NA's   :1        \n\n\nDo the values make sense?\nThere are some extreme values in the number of trips (more than 300?!) and average trip distance (more thank 2,000 KM?). We will remove them for this analysis. In practice, we should carefully make choices and justify them.\n\nperson_summary &lt;- person_summary %&gt;% \n  filter(number_of_trips &lt; 50 & avg_trip_distance &lt; 100)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Session 2 Data structures and descriptive statistics</span>"
    ]
  },
  {
    "objectID": "session-2.html#visualising-data",
    "href": "session-2.html#visualising-data",
    "title": "2  Session 2 Data structures and descriptive statistics",
    "section": "3.1 Visualising data",
    "text": "3.1 Visualising data\nUnivariate distribution: Check number of trips.\n\nperson_summary %&gt;% \n  ggplot(aes(number_of_trips)) +\n  geom_histogram() +\n  labs(\n    x = \"Total number of trips\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\nWhat is a suitable alternative to a histogram to visualise a variable distribution?\nBivariate plot: Visualise average number of trip and HH income.\n\nperson_summary %&gt;% \n  ggplot(aes(number_of_trips, hhincome_broad)) +\n  geom_boxplot() +\n  labs(\n    x = \"Total trips\",\n    y = \"Household income\"\n  )\n\n\n\n\n\n\n\n\nVisualise average trip distance and HH income.\n\nperson_summary %&gt;% \n  ggplot(aes(avg_trip_distance, hhincome_broad)) +\n  geom_boxplot() +\n  labs(\n    x = \"Average trip distance in kilometres\",\n    y = \"Household income\"\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Session 2 Data structures and descriptive statistics</span>"
    ]
  },
  {
    "objectID": "session-3.html",
    "href": "session-3.html",
    "title": "3  Session 3: Linear regression",
    "section": "",
    "text": "3.1 Preliminaries\nFor today’s session we will need the following packages. Install them using the install.packages() function if you don’t have them available.\n# Packages \nlibrary(tidyverse)\n\n# Today we will also be using\n# This is helpful to check the assumptions of linear models\nlibrary(performance)\nNow, we will read the data in to the R session. We will use three tables from the travel survey dataset.\n# Read data\ntrips &lt;- read_csv('data/Trips.csv')\npersons &lt;- read_csv('data/Persons.csv')\nhouseholds &lt;- read_csv('data/Households.csv')",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3: Linear regression</span>"
    ]
  },
  {
    "objectID": "session-3.html#preliminaries",
    "href": "session-3.html#preliminaries",
    "title": "3  Session 3: Linear regression",
    "section": "",
    "text": "You should have created an Rstudio project in Week 1. If you have not do so yet, I encourage you to return to a previous chapter for detailed instructions on data availability and structure.\nGet familiar with the dataset. If you haven’t do so, take a few minutes to look at the introduction to it is available at: https://www.psrc.org/media/3248, and the data dictionary, which is avaiable on Moodle, too.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3: Linear regression</span>"
    ]
  },
  {
    "objectID": "session-3.html#estimating-the-average-miles-driven-per-household-a-day",
    "href": "session-3.html#estimating-the-average-miles-driven-per-household-a-day",
    "title": "3  Session 3: Linear regression",
    "section": "3.2 Estimating the average miles driven per household a day",
    "text": "3.2 Estimating the average miles driven per household a day\nIn this first example, we are interested to know about driving behaviour. So, we will use the ‘trips’ table to summarise information, and supplement it with information from the ‘households’ table by joining these together.\nFirst, we will subset the trips which primary trip mode is ‘Drive’ only, for the year 2023.\n\ntrips_drive &lt;- trips %&gt;% \n  filter(grepl('Drive', mode_class) & survey_year == '2023')\n\nWhat is function grepl() doing in the previous chunk? How many observations were kept in for trips driving compared to all of the trips?\nThe we will create key variables relating to driving behaviour at the household level. We are crucially interested in the average miles driven a day per household. To do so, we summarise the information at the household level. Effectively, we sum the trip distance, and divide it by the number of days with trips recorded in the survey to obtain the average miles driven.\n\nmiles_driven_hh &lt;- trips_drive %&gt;% \n  group_by(household_id) %&gt;% \n  summarise(\n    total_miles_hh = sum(distance_miles, na.rm = TRUE),\n    num_days_trips = max(daynum),\n    avg_miles_driven = total_miles_hh / num_days_trips\n  )\n\nAs we now have a summary per household, we can join more information about the household using the ‘household_id’ unique identifier in the left_join() function.\n\n# Join household data\nmiles_driven_hh &lt;- miles_driven_hh %&gt;% \n  left_join(households, by = 'household_id')",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3: Linear regression</span>"
    ]
  },
  {
    "objectID": "session-3.html#exploratory-analysis",
    "href": "session-3.html#exploratory-analysis",
    "title": "3  Session 3: Linear regression",
    "section": "3.3 Exploratory analysis",
    "text": "3.3 Exploratory analysis\nIn this analysis, we will focus on respondents having more than 0 miles driven. In other words, only households who have reported to have droven in the survey.\n\n# Subset\nmiles_driven_hh &lt;- miles_driven_hh %&gt;% \n  filter(avg_miles_driven &gt; 0)\n\nLte’s visualize distribution of miles driven.\n\nmiles_driven_hh %&gt;% \n  ggplot(aes(avg_miles_driven)) +\n  geom_density() + \n  labs(x = 'Avg. miles driven per household', y = 'Density') +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSomething strange?…\nLet’s limit the maximum average of vehicle miles driven. The threshold chosen should be justified, e.g. preliminary information in the context, literature, or external empirical references.\n\nmiles_driven_hh &lt;- miles_driven_hh %&gt;% \n  filter(avg_miles_driven &lt;= 500)\n\n\n3.3.1 Bivariate analysis\nWe will transform the numchildren variables to factor, treating it as a categorical. Why? Are there options?\n\nmiles_driven_hh &lt;- miles_driven_hh %&gt;% \n  mutate(numchildren = factor(numchildren))\n\nPlot the distribution of the average vehicle miles driven by groups.\n\n# Plot distribution by groups\nmiles_driven_hh %&gt;% \n  ggplot(aes(numchildren, avg_miles_driven)) +\n  geom_boxplot() +\n  labs(x = 'Number of children', y = 'Avg. miles driven per household') +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3.3.2 How does working from home relates to vehicle miles driven?\nIn this session, the aim is to explain wow working from home relates to vehicle miles driven. For this, we will need to get the information about individuals in the household. We can do this using the ‘persons’ table.\nFirst, look at the categories in the ‘workplace’ variable\n\ncount(persons, workplace)\n\n# A tibble: 7 × 2\n  workplace                                                      n\n  &lt;chr&gt;                                                      &lt;int&gt;\n1 At home (telecommute or self-employed with home office)     2118\n2 Drives for a living (e.g., bus driver, salesperson)          257\n3 Missing: Skip Logic                                         7652\n4 Telework some days and travel to a work location some days  1554\n5 Usually the same location (outside home)                    8184\n6 Workplace regularly varies (different offices or jobsites)  1519\n7 &lt;NA&gt;                                                        2366\n\n\nThen, we create a new binary variable which identifies people working from home.\n\n# Create a binary variable indicating if anyone in works from home or teleworks\npersons &lt;- persons %&gt;% \n  mutate(\n    work_from_home = \n      ifelse(\n        # If the variable workplace contains 'At home' or 'Telework'\n        grepl('At home|Telework', workplace), \n        # return 'Yes'.\n        'Yes',\n        # Otherwise, we set it to 'No'\n        'No'\n))\n\nTo help you going about the previous code, you can read for more information about the conditional function typing ?ifelse in your R console.\nThen, we summarise the information at the household level summing the number of individuals at the household which work from home (‘pers_work_home’). Also, we will create another variable which checks if at leas one person works from home, i.e. ‘work_from_home’.\n\nwork_from_home &lt;- persons %&gt;% \n  group_by(household_id) %&gt;% \n  summarise(\n    pers_work_home = sum(work_from_home == 'Yes', na.rm = TRUE),\n    any_work_home = ifelse(pers_work_home &gt; 1, 'Yes', 'No')\n  )\n\nNow, we can join this new information to the data at the household level.\n\n# Join to subset\nmiles_driven_hh &lt;- miles_driven_hh %&gt;% \n  left_join(work_from_home, by = 'household_id')\n\nIs there any visual difference at the household level?\n\n# Visualise\nmiles_driven_hh %&gt;% \n  ggplot(aes(any_work_home, avg_miles_driven)) +\n  geom_boxplot() + \n  labs(\n    x = 'Any working from home', \n    y = 'Avg. miles driven per household'\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWhat about the descriptive statistics?\n\nmiles_driven_hh %&gt;% \n  group_by(any_work_home) %&gt;% \n  summarise(\n    miles_driven_mean = mean(avg_miles_driven),\n    miles_driven_sd = sd(avg_miles_driven)\n  )\n\n# A tibble: 2 × 3\n  any_work_home miles_driven_mean miles_driven_sd\n  &lt;chr&gt;                     &lt;dbl&gt;           &lt;dbl&gt;\n1 No                         37.2            46.0\n2 Yes                        37.7            41.6",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3: Linear regression</span>"
    ]
  },
  {
    "objectID": "session-3.html#evaluate-the-difference-in-a-linear-regression-analysis",
    "href": "session-3.html#evaluate-the-difference-in-a-linear-regression-analysis",
    "title": "3  Session 3: Linear regression",
    "section": "3.4 Evaluate the difference in a linear regression analysis",
    "text": "3.4 Evaluate the difference in a linear regression analysis\nLet’ see what a simple linear model suggest.\n\nmiles_driven_hh %&gt;% \n  lm(avg_miles_driven ~ any_work_home, .) %&gt;% \n  summary()\n\n\nCall:\nlm(formula = avg_miles_driven ~ any_work_home, data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-37.39 -26.82 -13.52   9.94 448.58 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       37.2208     0.9040  41.176   &lt;2e-16 ***\nany_work_homeYes   0.4514     2.8090   0.161    0.872    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 45.6 on 2837 degrees of freedom\nMultiple R-squared:  9.102e-06, Adjusted R-squared:  -0.0003434 \nF-statistic: 0.02582 on 1 and 2837 DF,  p-value: 0.8723\n\n\nAre there potential problems with this model or results?\nWe will add socio-demographic variables as controls, e.g. size of the household matters!\nFirst, we format the order of household income labels and convert size of household from character to numeric. This will ease interpretations.\n\n# Income labels\nincome_labs &lt;- c(\n  \"Under $25,000\", \n  \"$25,000-$49,999\", \n  \"$50,000-$74,999\", \n  \"$75,000-$99,999\", \n  \"$100,000-$199,000\", \n  \"$200,000 or more\"\n)\nmiles_driven_hh &lt;- miles_driven_hh %&gt;% \n  mutate(\n    # Income labels\n    hhincome_broad = factor(hhincome_broad, income_labs),\n    # Household size as integer\n    hhsize_int = readr::parse_number(hhsize, \"\\\\d+\"),\n    # Children at household as binary\n    children_binary = ifelse(numchildren == '0 children', 'No', 'Yes')\n)\n\nWe run the multiple regression and print results.\n\nm1 &lt;- miles_driven_hh %&gt;% \n  lm(\n    avg_miles_driven ~ \n      any_work_home + hhsize_int + hhincome_broad + children_binary, .\n  )\nsummary(m1)\n\n\nCall:\nlm(formula = avg_miles_driven ~ any_work_home + hhsize_int + \n    hhincome_broad + children_binary, data = .)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-79.13 -20.90 -10.19   7.86 427.12 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                       7.221      3.492   2.068 0.038836 *  \nany_work_homeYes                -13.542      3.740  -3.621 0.000302 ***\nhhsize_int                        8.655      1.216   7.119  1.6e-12 ***\nhhincome_broad$25,000-$49,999     5.295      3.796   1.395 0.163292    \nhhincome_broad$50,000-$74,999    12.670      3.704   3.421 0.000639 ***\nhhincome_broad$75,000-$99,999     9.266      3.808   2.433 0.015057 *  \nhhincome_broad$200,000 or more   14.640      3.827   3.826 0.000135 ***\nchildren_binaryYes                4.671      3.558   1.313 0.189411    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.46 on 1709 degrees of freedom\n  (1122 observations deleted due to missingness)\nMultiple R-squared:  0.09058,   Adjusted R-squared:  0.08685 \nF-statistic: 24.32 on 7 and 1709 DF,  p-value: &lt; 2.2e-16\n\n\nDiscuss the model results with your tutor.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3: Linear regression</span>"
    ]
  },
  {
    "objectID": "session-3.html#does-it-meet-the-model-assumptions-lets-check-the-model",
    "href": "session-3.html#does-it-meet-the-model-assumptions-lets-check-the-model",
    "title": "3  Session 3: Linear regression",
    "section": "3.5 Does it meet the model assumptions? … Lets check the model",
    "text": "3.5 Does it meet the model assumptions? … Lets check the model\nCheck model 1 assumptions. Type ‘y’ when you are asked about updating extensions.\n\ncheck_model(m1)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3: Linear regression</span>"
    ]
  },
  {
    "objectID": "session-3.html#a-log-linear-model",
    "href": "session-3.html#a-log-linear-model",
    "title": "3  Session 3: Linear regression",
    "section": "3.6 A log-linear model",
    "text": "3.6 A log-linear model\nLets try to fit the model in the log-linear form.\n\nm2 &lt;- miles_driven_hh %&gt;% \n  mutate(log_miles_driven = log(avg_miles_driven)) %&gt;% \n  lm(\n    log_miles_driven ~ \n      any_work_home + hhsize_int + hhincome_broad + children_binary, .\n)\n\nAnd check the model again\n\ncheck_model(m2)\n\n\n\n\n\n\n\n\nWhat are the interpretations of the log-linear model? Think of coefficients and overall performance.\n\nsummary(m2)\n\n\nCall:\nlm(formula = log_miles_driven ~ any_work_home + hhsize_int + \n    hhincome_broad + children_binary, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.7196 -0.6662  0.1538  0.7842  3.5868 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     1.89172    0.09885  19.137  &lt; 2e-16 ***\nany_work_homeYes               -0.32932    0.10585  -3.111  0.00189 ** \nhhsize_int                      0.26181    0.03441   7.608 4.57e-14 ***\nhhincome_broad$25,000-$49,999   0.29507    0.10746   2.746  0.00610 ** \nhhincome_broad$50,000-$74,999   0.55532    0.10483   5.297 1.33e-07 ***\nhhincome_broad$75,000-$99,999   0.54681    0.10777   5.074 4.32e-07 ***\nhhincome_broad$200,000 or more  0.75548    0.10832   6.975 4.36e-12 ***\nchildren_binaryYes              0.08674    0.10071   0.861  0.38918    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.173 on 1709 degrees of freedom\n  (1122 observations deleted due to missingness)\nMultiple R-squared:  0.1218,    Adjusted R-squared:  0.1182 \nF-statistic: 33.85 on 7 and 1709 DF,  p-value: &lt; 2.2e-16\n\n\nWhich model would you choose? Are the any other potentially omitted variables?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Session 3: Linear regression</span>"
    ]
  },
  {
    "objectID": "session-4.html",
    "href": "session-4.html",
    "title": "4  Session 4: Logistic regression Part 1",
    "section": "",
    "text": "5 Preliminaries\nWe will continue to work with the Puget Sound Household Travel Survey. If you do not have the data or project set for this, please check the preliminary instructions for Week 1.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Session 4: Logistic regression Part 1</span>"
    ]
  },
  {
    "objectID": "session-4.html#data-manipulation",
    "href": "session-4.html#data-manipulation",
    "title": "4  Session 4: Logistic regression Part 1",
    "section": "5.1 Data manipulation",
    "text": "5.1 Data manipulation\nFor today’s session we will need the following packages.\n\n# Packages \nlibrary(tidyverse) # For data manipulation\nlibrary(gtsummary) # Descriptive statistics\nlibrary(performance) # Model checks\n\nYou will also need to install a helper package: install.packages(\"broom.helpers\").\nNow, we will read the data in to the R session. We will need information from trips, persons, and households tables.\n\n# Load data\nhouseholds &lt;- \n  read_csv('data/Households.csv')\npersons &lt;- \n  read_csv('data/Persons.csv')\ntrips &lt;- \n  read_csv('data/Trips.csv')\n\nWe will work with data for the year 2023 only.\n\n# Filter data for the year 2023 only\nhouseholds &lt;- households %&gt;% filter(survey_year == 2023)\ntrips &lt;- trips %&gt;% filter(survey_year == 2023)\npersons &lt;- persons %&gt;% filter(survey_year == 2023)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Session 4: Logistic regression Part 1</span>"
    ]
  },
  {
    "objectID": "session-4.html#summarising-data-at-the-appropriate-level",
    "href": "session-4.html#summarising-data-at-the-appropriate-level",
    "title": "4  Session 4: Logistic regression Part 1",
    "section": "5.2 Summarising data at the appropriate level",
    "text": "5.2 Summarising data at the appropriate level\nThe dependent variable we are interested in is whether the travellers used an active transport mode or not to travel to work. This is a binary variable, so we will use logistic regression to identify the relationships with other variables.\nHere, we focus on trips to work only.\n\ntrips_work &lt;- trips %&gt;% \n  filter('Work' == dest_purpose_cat)\n\nThe criteria for constructing this variable is that the person has made at least one trip to work during the reported week. We obtain this information at the trip level and summarise it at the person level, as shown below:\n\n# Summarise trip data at the person level\ntrips_summary &lt;- trips_work %&gt;% \n  group_by(person_id) %&gt;% \n  summarise(\n    active = ifelse(any(grepl('Walk|Bike', mode_class)), 1, 0), \n    total_miles = sum(distance_miles, na.rm = TRUE),\n    num_days_trips = max(daynum),\n    avg_distance = total_miles / num_days_trips\n)\n\nRemember, persons can generate many trips a day and use different modes. This is why we need to summarise the trip data at the person level.\nWe keep persons who reported trips to work only, and whose distance is less than 50 miles. This can be a reasonable threshold, as we are interested in active transport modes. In practice, it is always important to justify choices, e.g. literature, expert opinion, or empirical evidence.\n\ntrips_summary &lt;- trips_summary %&gt;% \n  filter(num_days_trips &gt; 0 & avg_distance &lt; 50)\n\nHow many respondents use an active travel mode to go to work?\n\n5.2.1 Independent variables\nNow, in addition to the travel behaviour information for people, we want to know more about the demographics and characteristics of the household. Thus, we join the trip summary and household data at the person level.\n\npersons_main &lt;- persons %&gt;% \n  left_join(trips_summary, by = 'person_id') %&gt;% \n  left_join(households, by = 'household_id')\n\nNext, we format the independent variables and simplify some of these.\nNote that we will also create the key independent variable, namely: having free parking at work. We wish to examine if and how this is related to the use of active transport modes. We are also including further demographic control variables at the person and household level.\n\n# Write the name and appropriate order of the levels for hhincome_broad\nincome_labs &lt;- c(\n  'Under $25,000', '$25,000-$49,999', '$50,000-$74,999', \n  '$75,000-$99,999', '$100,000-$199,999', '$200,000 or more'\n)\n\n# Format and create appropriate variables\npersons_main &lt;- persons_main %&gt;% \n  mutate(\n    # Whether person has free parking at work\n    free_parking = ifelse(commute_subsidy_3 == 'Selected', 'Yes', 'No'),\n    # Simplify educaton, e.g. graduate and bachelor vs all other\n    higher_education = ifelse(\n      grepl('Graduate|Bachelor', education, ignore.case = TRUE), 'Yes', 'No'\n    ),\n    children = ifelse(numchildren == '0 children', 'No', 'Yes'),\n    hhincome_broad = factor(hhincome_broad, levels = income_labs)\n)\n\nBefore moving to the analysis, we will keep only complete observations for the variables of interest.\nWe will also remove incomplete cases, meaning persons who have missing data in any of the relevant columns. It’s important to be cautious with this step, especially when dealing with supplementary variables where missing values are expected. For example, the ‘age of children’ variable may have missing data for persons without children, which should be handled appropriately. Otherwise, you might end up removing valuable information.\n\n# First, select variables of interest\npersons_main &lt;- persons_main %&gt;% \n  select(\n    active, \n    free_parking,\n    avg_distance,\n    gender,\n    higher_education,\n    children,\n    hhincome_broad\n  )\n\n# Then, removing incomplete observations\npersons_main &lt;- persons_main %&gt;% \n  drop_na()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Session 4: Logistic regression Part 1</span>"
    ]
  },
  {
    "objectID": "session-4.html#model-checks",
    "href": "session-4.html#model-checks",
    "title": "4  Session 4: Logistic regression Part 1",
    "section": "8.1 Model checks",
    "text": "8.1 Model checks\nThe following function provides a the McFadden pseudo-r-squared measure.\n\nr2_mcfadden(logit_model1)\n\n# R2 for Generalized Linear Regression\n       R2: 0.216\n  adj. R2: 0.215\n\n\nWe can also check the percentage of correct predictions.\n\nperformance_pcp(logit_model1)\n\n# Percentage of Correct Predictions from Logistic Regression Model\n\n  Full model: 70.54% [68.36% - 72.72%]\n  Null model: 61.18% [58.85% - 63.51%]\n\n# Likelihood-Ratio-Test\n\n  Chi-squared: 418.031\n  df:  12.000\n  p-value:   0.000\n\n\nThere are generally three assumptions for the logit model: 1) independence of observations; 2) linearity; and 3) no perfect multicollinearity.\nWe can check for collinearity using the variance of inflation factor (VIF).\n\ncheck_collinearity(logit_model1)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     free_parking 1.02 [1.00, 1.38]         1.01      0.99     [0.73, 1.00]\n     avg_distance 1.03 [1.00, 1.17]         1.01      0.97     [0.85, 1.00]\n           gender 1.07 [1.03, 1.15]         1.03      0.94     [0.87, 0.97]\n higher_education 1.07 [1.03, 1.15]         1.04      0.93     [0.87, 0.97]\n         children 1.06 [1.03, 1.15]         1.03      0.94     [0.87, 0.97]\n   hhincome_broad 1.21 [1.15, 1.29]         1.10      0.83     [0.78, 0.87]\n\n\nWe can check linearity examining the relationship between each continuous predictor and log-odds of the predicted probabilities. In our model, we only have one continuous variable. We can check the linearity of our model as following:\n\n# Harrys J.K. 2019, Statistics With R: Solving Problems Using Real-World Data\n# SAGE Publications. (p. 651)\n\n# Compute a variable of the log-odds of the predicted values\nlogit_pred &lt;- log(logit_model1$fitted.values / (1- logit_model1$fitted.values))\n\n# Create a small data frame with the log-odds and the distance predictor\nlinearity_data1 &lt;- \n  data.frame(\n    logit_pred, \n    avg_distance = logit_model1$model$avg_distance\n)\n\n# Plot\nlinearity_data1 %&gt;% \n  ggplot(aes(avg_distance, logit_pred)) +\n  geom_point() +\n  geom_smooth(method = 'loess', aes(col = 'Loess curve'), se = FALSE) +\n  geom_smooth(method = 'lm', aes(col = 'Linear fit'), se = FALSE) +\n  labs(\n    x = \"Avg. distance to work (in miles)\",\n    y= \"Log-odds of active travel \\npredicted probability\"\n  )\n\n\n\n\n\n\n\n\nWe should check whether the predictions are equally accurate along the range of values of the predictor.\nIndependence is related to the structure and collection methods of data. To what extend does our model and data meet the independence assumption?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Session 4: Logistic regression Part 1</span>"
    ]
  },
  {
    "objectID": "session-6.html",
    "href": "session-6.html",
    "title": "5  Session 6: Multinomial model",
    "section": "",
    "text": "6 Introduction\nWe will continue to work with the Puget Sound Household Travel Survey Version 2023.4. If you do not have the data or project set for this, please check the preliminary instructions for Week 3.\nMultinomial regression is useful when the dependent variable is categorical and has more than two categories. This week, we’ll build on the logistic regression example from last week, where we explored mode choice for work trips and how free parking influences that decision. This time, we’ll break down mode choice at the person level, with three possible outcomes: driving, active travel, or transit.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Session 6: Multinomial model</span>"
    ]
  },
  {
    "objectID": "session-6.html#preliminaries",
    "href": "session-6.html#preliminaries",
    "title": "5  Session 6: Multinomial model",
    "section": "6.1 Preliminaries",
    "text": "6.1 Preliminaries\nFor today’s session we will need the following packages.\n\n# Packages \nlibrary(tidyverse) # For data manipulation\nlibrary(gtsummary) # Descriptive statistics\nlibrary(nnet) # For multinomial regression\nlibrary(caret) # To check the accuracy of the model\nlibrary(performance) # For model fit measures\n\nAs before, we read the data in to the R session. Again, we will obtian information from trips, persons, and households tables.\n\n# Load data\ntrips &lt;- read_csv('data/Trips.csv')\npersons &lt;- read_csv('data/Persons.csv')\nhouseholds &lt;- read_csv('data/Households.csv')\n\nWe limit the data for the year 2023 only.\n\n# Filter data for the year 2023 only\nhouseholds &lt;- households %&gt;% filter(survey_year == 2023)\ntrips &lt;- trips %&gt;% filter(survey_year == 2023)\npersons &lt;- persons %&gt;% filter(survey_year == 2023)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Session 6: Multinomial model</span>"
    ]
  },
  {
    "objectID": "session-6.html#dependent-variable-main-mode-choice-to-work-per-person",
    "href": "session-6.html#dependent-variable-main-mode-choice-to-work-per-person",
    "title": "5  Session 6: Multinomial model",
    "section": "6.2 Dependent variable: Main mode choice to work per person",
    "text": "6.2 Dependent variable: Main mode choice to work per person\nHere, we focus on trips to work. So, we keep trips which its destination is ‘Work’ only.\n\ntrips_work &lt;- trips %&gt;% \n  filter('Work' == dest_purpose_cat)\n\nNote that in the outcomes must be mutually exclusive. This means we need to identify only one ‘main’ mode of transport for each person when travelling to work.\nFor this exercise, we’ll define the main mode as the one that is used most frequently. If a person reported using more than one mode the same number of times, we’ll select the one that covered the greatest distance. To start, we’ll summarise the frequency and distance reported for each person and each mode.\n\nmode_summary &lt;- trips_work %&gt;% \n  group_by(person_id, mode_class) %&gt;% \n  summarise(\n    mode_frequency = n(),\n    mode_distance = sum(distance_miles, na.rm = TRUE),\n  ) \n\nAnd, we have a quick look to the result:\n\nmode_summary\n\n# A tibble: 2,137 × 4\n# Groups:   person_id [1,821]\n    person_id mode_class mode_frequency mode_distance\n        &lt;dbl&gt; &lt;chr&gt;               &lt;int&gt;         &lt;dbl&gt;\n 1 2300017304 Drive SOV               4         16.2 \n 2 2300021301 Bike                    1          1.36\n 3 2300074501 Transit                 5         25.1 \n 4 2300082802 Transit                 1          2.07\n 5 2300116701 Drive SOV               1         25.2 \n 6 2300124701 Drive SOV               1          3.90\n 7 2300124702 Bike                    1          2.35\n 8 2300124702 Drive SOV               2          5.15\n 9 2300132201 Drive SOV               3         11.2 \n10 2300149601 Transit                 1          9.64\n# ℹ 2,127 more rows\n\n\nNow, we’ll select the most frequently used mode for each individual. If there’s a tie, we’ll choose the mode that covered the most miles.\n\n# Define only one 'main' mode per person based on frequency and distance\nmode_main &lt;- mode_summary %&gt;% \n  group_by(person_id) %&gt;% \n  # Keep the most frequent modes per individual\n  slice_max(order_by = mode_frequency, with_ties = TRUE) %&gt;% \n  # If tied, pick the one with more miles\n  slice_max(order_by = mode_distance, with_ties = FALSE)  %&gt;% \n  ungroup()\n\nFor simplicity in our model, we will group mode into three broader classes, namely: Drive, Transit, and Active. For this exercise, we drop all other classes.\n\n# reclassify\nmode_main &lt;- mode_main %&gt;% \n  mutate(\n    mode_main = case_when(\n      grepl('Drive', mode_class) ~ 'Drive',\n      grepl('Transit', mode_class) ~ 'Transit',\n      grepl('Bike|Walk', mode_class) ~ 'Active',\n      # All other classes are ignored using NA\n      TRUE ~ NA\n    )\n  )\n\n# Keep only relevant column, i.e. main mode per individual\nmode_main &lt;- mode_main %&gt;% \n  select(person_id, mode_main)\n\nHow is the distribution of the main mode looking?\n\ncount(mode_main, mode_main)\n\n# A tibble: 4 × 2\n  mode_main     n\n  &lt;chr&gt;     &lt;int&gt;\n1 Active      336\n2 Drive      1190\n3 Transit     258\n4 &lt;NA&gt;         37",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Session 6: Multinomial model</span>"
    ]
  },
  {
    "objectID": "session-6.html#independent-variables",
    "href": "session-6.html#independent-variables",
    "title": "5  Session 6: Multinomial model",
    "section": "6.3 Independent variables",
    "text": "6.3 Independent variables\nIn addition to the dependent variable (mode choice in three categories), we need to define the independent variables that we think are related to mode choice to work. For this, we include information from trips, individual, and households.\nWe summarise trip information to work at the person level.\n\ntrips_distance &lt;- trips_work %&gt;% \n  group_by(person_id) %&gt;% \n  summarise(\n    total_miles = sum(distance_miles, na.rm = TRUE),\n    num_days_trips = max(daynum),\n    avg_distance = total_miles / num_days_trips\n  ) %&gt;% \n  filter(num_days_trips &gt; 0 & avg_distance &lt; 100)\n\nLater, we supplement the dependent variable information with trips, persons, and households.\n\n# Join the tables together\npersons_main &lt;- mode_main %&gt;% \n  left_join(trips_distance, by = 'person_id') %&gt;% \n  left_join(persons, by = 'person_id') %&gt;%\n  left_join(households, by = 'household_id')\n\nHave a look to the number of observations in persons_main compared to persons. Why do we see this difference?\nAs in our prior lab, we format and label the variables that we will use:\n\n# Write the name and appropriate order of the levels for hhincome_broad\nincome_labs &lt;- c(\n  'Under $25,000', '$25,000-$49,999', '$50,000-$74,999', \n  '$75,000-$99,999', '$100,000-$199,999', '$200,000 or more'\n)\n\n# Format and create appropriate variables\npersons_main &lt;- persons_main %&gt;% \n  mutate(\n    # Whether person has free parking at work\n    free_parking = ifelse(commute_subsidy_3 == 'Selected', 'Yes', 'No'),\n    # Simplify educaton, e.g. graduate and bachelor vs all other\n    higher_education = ifelse(\n      grepl('Graduate|Bachelor', education, ignore.case = TRUE), 'Yes', 'No'),\n    children = ifelse(numchildren == '0 children', 'No', 'Yes'),\n    hhincome_broad = factor(hhincome_broad, levels = income_labs)\n  )\n\nAn we keep only the variables of interest for now.\n\n# First, select variables of interest\npersons_main &lt;- persons_main %&gt;% \n  select(\n    mode_main, \n    free_parking,\n    avg_distance,\n    gender,\n    higher_education,\n    children,\n    hhincome_broad\n  )\n\n# We also remove incomplete observations\npersons_main &lt;- persons_main %&gt;% \n  drop_na()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Session 6: Multinomial model</span>"
    ]
  },
  {
    "objectID": "session-6.html#measures-of-fit",
    "href": "session-6.html#measures-of-fit",
    "title": "5  Session 6: Multinomial model",
    "section": "8.1 Measures of fit",
    "text": "8.1 Measures of fit\nWe can compute a pseudo-r-squared value and other measures too:\n\n# Measures of fit\nmodel_performance(multinomial_model1)\n\nCan't calculate log-loss.\n\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------------\n2289.773 | 2290.105 | 2376.377 | 0.217 |     0.216 | 0.360 | 1.173\n\n\nAs with logistic regression, we can use the Akaike information criterion (AIC). Lower AIC values indicate a better-fitting model, i.e., a model that haves a good balance between goodness of fit and complexity.\nFrom the table the column ‘R2 (adj.)’ corresponds to McFadden’s pseudo R-squared values. This value ranges from 0 to 1. Higher values indicate a better-fitting model.\nAdditionally, we can look at the predictions. For instance, the model predictions look as following:\n\n# Model predictions\nmultinomial_model1$fitted.values[1:6, ]\n\n      Drive    Active   Transit\n1 0.6800683 0.2026791 0.1172526\n2 0.2445990 0.5802809 0.1751201\n3 0.4327570 0.2992778 0.2679652\n4 0.2910892 0.5079115 0.2009993\n5 0.6078908 0.2817081 0.1104011\n6 0.5549170 0.3047215 0.1403615\n\npredict(multinomial_model1)[1:6]\n\n[1] Drive  Active Drive  Active Drive  Drive \nLevels: Drive Active Transit\n\n\nWe can check these predictions against observed data using a confusion matrix, and related measures:\n\n# Correctly predicted classes\npredicted_classes &lt;- predict(multinomial_model1)\nconfusionMatrix(predicted_classes, persons_main$mode_main)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Drive Active Transit\n   Drive    1010    127     195\n   Active     88    191      45\n   Transit     0      0       1\n\nOverall Statistics\n                                          \n               Accuracy : 0.7254          \n                 95% CI : (0.7032, 0.7468)\n    No Information Rate : 0.6626          \n    P-Value [Acc &gt; NIR] : 2.277e-08       \n                                          \n                  Kappa : 0.361           \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n\nStatistics by Class:\n\n                     Class: Drive Class: Active Class: Transit\nSensitivity                0.9199        0.6006      0.0041494\nSpecificity                0.4240        0.9007      1.0000000\nPos Pred Value             0.7583        0.5895      1.0000000\nNeg Pred Value             0.7292        0.9047      0.8550725\nPrevalence                 0.6626        0.1919      0.1454436\nDetection Rate             0.6095        0.1153      0.0006035\nDetection Prevalence       0.8039        0.1955      0.0006035\nBalanced Accuracy          0.6719        0.7507      0.5020747\n\n\nThe diagonal of the matrix indicates the number of correct predictions. The sensitivity indicates the percentage of correct predictions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Session 6: Multinomial model</span>"
    ]
  },
  {
    "objectID": "session-7.html",
    "href": "session-7.html",
    "title": "6  Session 7: Poisson regression",
    "section": "",
    "text": "7 Introduction\nWe will now explore count models, which are relevant in transport applications for modelling variables such as the number of trips, number of vehicles, or number of collisions.\nThe Poisson model is well suited to discrete numeric outcomes ranging from 0 to infinity. Unlike linear regression, Poisson models do not allow negative values. Today, we will examine the number of active travel trips at the household level.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Session 7: Poisson regression</span>"
    ]
  },
  {
    "objectID": "session-7.html#preliminaries",
    "href": "session-7.html#preliminaries",
    "title": "6  Session 7: Poisson regression",
    "section": "7.1 Preliminaries",
    "text": "7.1 Preliminaries\nFor today’s session we will need the following packages.\n\n# Packages \nlibrary(tidyverse) # For data manipulation\nlibrary(gtsummary) # Descriptive statistics\nlibrary(performance) # For model fit measures\n\nThis time, we will need information from trips and households tables only.\n\n# Load data\ntrips &lt;- read_csv('data/Trips.csv')\nhouseholds &lt;- read_csv('data/Households.csv')\n\nWe limit the data for the year 2023 only.\n\n# Filter data for the year 2023 only\nhouseholds &lt;- households %&gt;% filter(survey_year == 2023)\ntrips &lt;- trips %&gt;% filter(survey_year == 2023)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Session 7: Poisson regression</span>"
    ]
  },
  {
    "objectID": "session-7.html#dependent-variable-number-of-active-travel-trips",
    "href": "session-7.html#dependent-variable-number-of-active-travel-trips",
    "title": "6  Session 7: Poisson regression",
    "section": "7.2 Dependent variable: Number of active travel trips",
    "text": "7.2 Dependent variable: Number of active travel trips\nWe will consider trips that were completed using active travel modes, regardless of the purpose.\n\nactive_trips &lt;- trips %&gt;%\n  filter(mode_class == 'Bike' | mode_class == 'Walk')\n\nNext, we count the number of active travel trip for each household.\n\n# Summarise trips by household\ntrips_summary &lt;- active_trips %&gt;% \n  group_by(household_id) %&gt;% \n  summarise(active_trips = n())\n\nHow many households report active travel trips?\nNote that the above does not include households with 0 active mode trips. So, this analysis focuses on the intensity of active travel use e.g. household who have reported at least 1 active travel trip.\nLet’s look at the distribution, and variace.\n\nsummary(trips_summary$active_trips)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   2.000   4.000   8.584  10.000  98.000 \n\nvar(trips_summary$active_trips)\n\n[1] 128.6674\n\n\nDoes the variance approximate the mean?\nRemember that this is a key assumption in Poisson regression.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Session 7: Poisson regression</span>"
    ]
  },
  {
    "objectID": "session-7.html#independent-variables",
    "href": "session-7.html#independent-variables",
    "title": "6  Session 7: Poisson regression",
    "section": "7.3 Independent variables",
    "text": "7.3 Independent variables\nIn addition to the dependent variable (trip count), we need to define the independent variables that we think are related to mode choice to work. For this, we include information from households. So, we supplement the dependent variable information with trips, persons, and households.\n\n# Join the tables together\nhouseholds_main &lt;- trips_summary %&gt;% \n  left_join(households, by = 'household_id')\n\nHere, order matters, e.g. we join the number of active trips to all households. So, we exclude all of the households which did not reported active travel trips.\nAs in our prior lab, we format and label the variables that we will use in the analysis:\n\n# HH income labs\nincome_labs &lt;- c(\n  'Under $25,000', '$25,000-$49,999', '$50,000-$74,999', \n  '$75,000-$99,999', '$100,000-$199,999', '$200,000 or more'\n)\n\n# Format and create appropriate variables\nhouseholds_main &lt;- households_main &lt;- households_main %&gt;% \n  mutate(\n    children = ifelse(numchildren == '0 children', 'No', 'Yes'),\n    hhincome_broad = factor(hhincome_broad, levels = income_labs),\n    hhsize_int = as.numeric(str_extract(hhsize, \"\\\\d+\")),\n    vehicle_broad = case_when(\n      vehicle_count == '0 (no vehicles)' ~  '0 (no vehicles)',\n      vehicle_count == '1 vehicle' ~  '1 vehicle',\n      TRUE ~ '2 or more'\n    ),\n  )\n\nAn we keep only the variables of interest for now.\n\n# First, select variables of interest\nhouseholds_main &lt;- households_main %&gt;% \n  select(\n    active_trips,\n    children, \n    vehicle_broad,\n    hhincome_broad,\n    hhsize_int,\n    numdayscomplete,\n    vehicle_broad\n  )\n\n# We also remove incomplete observations\nhouseholds_main &lt;- households_main %&gt;% \n  drop_na()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Session 7: Poisson regression</span>"
    ]
  },
  {
    "objectID": "session-7.html#model-assumption-checks",
    "href": "session-7.html#model-assumption-checks",
    "title": "6  Session 7: Poisson regression",
    "section": "9.1 Model assumption checks",
    "text": "9.1 Model assumption checks\nOne of the key assumptions of the Poisson model is that the mean is equal to the variance. Dispersion can occur when the data is more variable than the model assumes. This can yield to estimation problems, such as underestimated errors (e.g. we can conclude something is significant when it is not), or poor model fit.\nWe can easily test for over dispersion with the perfomance:: package as following:\n\ncheck_overdispersion(poisson_m1)\n\n# Overdispersion test\n\n       dispersion ratio =     8.978\n  Pearson's Chi-Squared = 13242.418\n                p-value =   &lt; 0.001\n\n\nFrom this test, the dispersion ratio should be close to 1. From the results we see that this is much larger, and the p-value is lower than 0.05. Thus, we can could that overdispersion is present.\nA common alternative, is to use a negative binomial model. This is also useful to model counts and does not assume that the variance is roughly similar to the mean of our count. Thus, this is appropriate when overdispersion is high. For this, we will require the glm.nb() function of the MASS:: package.\n\nlibrary(MASS)\n\n# Fit the negative binomial model\nnegbin_m2 &lt;- glm.nb(\n  formula = active_trips ~ children + vehicle_broad + hhsize_int + numdayscomplete, \n  data = households_main\n)\n\n# An we print the summary of the model\nnegbin_m2 %&gt;% \n  tbl_regression(exponentiate = TRUE) %&gt;% \n  add_glance_table()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nIRR\n95% CI\np-value\n\n\n\n\nchildren\n\n\n\n\n\n\n\n\n    No\n—\n—\n\n\n\n\n    Yes\n2.57\n2.16, 3.05\n&lt;0.001\n\n\nvehicle_broad\n\n\n\n\n\n\n\n\n    0 (no vehicles)\n—\n—\n\n\n\n\n    1 vehicle\n0.95\n0.85, 1.06\n0.4\n\n\n    2 or more\n0.73\n0.63, 0.83\n&lt;0.001\n\n\nhhsize_int\n1.19\n1.12, 1.28\n&lt;0.001\n\n\nnumdayscomplete\n\n\n\n\n\n\n\n\n    1\n—\n—\n\n\n\n\n    2\n2.03\n1.02, 4.52\n0.060\n\n\n    3\n4.12\n2.79, 6.34\n&lt;0.001\n\n\n    4\n5.15\n3.54, 7.79\n&lt;0.001\n\n\n    5\n4.85\n3.86, 6.17\n&lt;0.001\n\n\n    6\n4.24\n3.66, 4.93\n&lt;0.001\n\n\n    7\n4.13\n3.70, 4.60\n&lt;0.001\n\n\nNull deviance\n2,366\n\n\n\n\n\n\nNull df\n1,485\n\n\n\n\n\n\nLog-likelihood\n-4,418\n\n\n\n\n\n\nAIC\n8,860\n\n\n\n\n\n\nBIC\n8,924\n\n\n\n\n\n\nDeviance\n1,451\n\n\n\n\n\n\nResidual df\n1,475\n\n\n\n\n\n\nNo. Obs.\n1,486\n\n\n\n\n\n\n\nAbbreviations: CI = Confidence Interval, IRR = Incidence Rate Ratio\n\n\n\n\n\n\n\n\nCan you identify key differences compared to the Poisson model? The interpretation of coefficients is very similar.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Session 7: Poisson regression</span>"
    ]
  }
]